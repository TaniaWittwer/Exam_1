---
title: "Delinquence early predictor - longitudinal study"
author: "Tania Wittwer"
output:
  tufte::tufte_html: default
  tufte::tufte_handout: default
---

##Preliminary steps
#Load packages
```{r, mysize = TRUE, size="\\scriptsize"}
#install.packages("pacman")
library(pacman)
p_load(tidyverse, haven, tufte, knitr, magrittr, psych, stats, caret, fmsb, DHARMa, boot, broom, tree)
```

#Load datafiles
```{r, mysize = TRUE, size="\\scriptsize"}
delinquency <- read_spss("Cambridge_delinquency_with_caseid.sav")
conviction <- read_spss("conviction_data.sav")
```

#Summary of the data
Donald West and David Farrington collected data of 411 British boys/men of working class area in Cambridge. Data were collected from 1961 to 1981 though different survey and interviews with the boys, parents enven teacher. A the beginning, boys were aged of 8-9 years old. The purpose of the Study was to explore potential predictors of delinquency.


##QUESTION 1
According to the question, we need to select variables which could be "early predictors of criminality". Therefore, I have only choosen variables collected before 10 years old, according the what have been found previously by Krohn (2006) and Kazemian (2011).
Thus, chosen variables as potential predictors are the following (name from the Codebook, with number of the variable): conduct disorder of boy (53), discipline quality of father (62) and mother (63), family size (69), housing - care of interior (83), inconsistency in disagreement between parents (89), interest in education by parents (91), job record of father (96), nervousness of boy (104), number of friends of boy (105), outgoing or withdrawn boy (117), paternal attitude (118), progressive matrices IQ (119), physical neglect of boy (123), peer rating popularity (125), sibling disturbance (137), socioeconomic status of family (138), teacher rating: poor attendance (155)
```{r, mysize = TRUE, size="\\scriptsize"}
predictors_1 <- 
  delinquency %>% 
  select(v4, v53, v62, v63, v69, v83, v89, v91, v96, v104, v105, v117, v118, v119, v123, v125, v137, v138, v155)

predictor_1 <- rename(predictors_1, id = v4, conduct = v53, disc_dad = v62, disc_mum = v63, familysize = v69, housecare = v83, betw_parents = v89, educ_interest = v91, job_dad = v96, nervousness = v104, friends = v105, withdrawn = v117, attitude_dad = v118, iq = v119, phys_neglect = v123, popularity = v125, sibl_disturb = v137, socioeco_fam = v138, attendance = v155)

#Give labels to variables for clarity in tables
predictor_1$conduct <- factor(predictor_1$conduct,
                              levels = c(0,1,2,3),
                              labels = c("unknown", "well", "moderatebad", "verybadly"))
predictor_1$disc_dad <- factor(predictor_1$disc_dad,
                              levels = c(0,1,2,3,4,5),
                              labels = c("unknown", "not", "spoilt", "harsh", "disinterest", "NA"))
predictor_1$disc_mum <- factor(predictor_1$disc_mum,
                              levels = c(0,1,2,3,4,5),
                              labels = c("unknown", "not", "spoilt", "harsh", "disinterest", "NA"))
predictor_1$familysize <- factor(predictor_1$familysize,
                              levels = c(1,2,3,4,5,6),
                              labels = c("none", "one", "two", "three", "four", "five_more"))
predictor_1$housecare <- factor(predictor_1$housecare,
                              levels = c(0,1,2),
                              labels = c("unknown", "satisfactory", "veryneglected"))
predictor_1$betw_parents <- factor(predictor_1$betw_parents,
                              levels = c(0,1,2,3),
                              labels = c("unknown", "consistency", "inconsistency", "NA"))
predictor_1$educ_interest <- factor(predictor_1$educ_interest,
                              levels = c(0,1,2,3),
                              labels = c("unknown", "veryinterested", "average", "notinterested"))
predictor_1$job_dad <- factor(predictor_1$job_dad,
                              levels = c(0,1,2,3,4),
                              labels = c("unknown", "alwstable", "nowstable", "erractic", "NA"))
predictor_1$nervousness <- factor(predictor_1$nervousness,
                              levels = c(0,1,2,3,4),
                              labels = c("unknown", "not", "minimal", "moderate", "severe"))
predictor_1$friends <- factor(predictor_1$friends,
                              levels = c(0,1,2,3),
                              labels = c("unknown", "many", "average", "fewornot"))
predictor_1$withdrawn <- factor(predictor_1$withdrawn,
                              levels = c(0,1,2,3),
                              labels = c("unknown", "atease", "normal", "shyorwithdrawn"))
predictor_1$attitude_dad <- factor(predictor_1$attitude_dad,
                              levels = c(0,1,2,3,4,5,6),
                              labels = c("unknown", "warm", "passive", "cruel", "neglected", "absent", "dead"))
predictor_1$iq <- factor(predictor_1$iq,
                              levels = c(1,2,3,4),
                              labels = c("min111", "101-110", "91-100", "max90"))
predictor_1$phys_neglect <- factor(predictor_1$phys_neglect,
                              levels = c(0,1,2),
                              labels = c("unknown", "absent", "present"))
predictor_1$popularity <- factor(predictor_1$popularity,
                              levels = c(0,1,2,3,4),
                              labels = c("unknown", "popular", "averagepop", "averageunpop", "unpopular"))
predictor_1$sibl_disturb <- factor(predictor_1$sibl_disturb,
                              levels = c(0,1,2,3),
                              labels = c("unknown", "none", "distrubance", "NA"))
predictor_1$socioeco_fam <- factor(predictor_1$socioeco_fam,
                              levels = c(1,2,3,4,5,6),
                              labels = c("II-NM", "III-NM", "III-M", "IV-NM", "IV-M", "V"))
predictor_1$attendance <- factor(predictor_1$attendance,
                              levels = c(0,1,2),
                              labels = c("unknown", "satisfactory", "truance_abstsm"))
```

In addition, variables on conviction were selected to create a dichotomous binary variable: convicted vs non-convicted (without taking into account neither the age of conviction(s), nor the number of conviction)
```{r, mysize = TRUE, size="\\scriptsize"}
#rename to avoid 'variable not found' problem
conviction <- rename(conviction, id = icpsr_seq_id_number)

#make a wide table
conviction_spread <- 
  spread(data = conviction, key = id, value = convicted)

#select only variable containing conviction as adult or juvenile
conviction2a <- conviction_spread[6,]
conviction2b <- conviction_spread[7,]

#make a long table and rename to avoid matching error and for clarity
conviction3a <- 
  gather(conviction2a, key = id, value = agecat) %>% 
  rename(as_adult = agecat)
conviction3b <- 
  gather(conviction2b, key = id, value = agecat) %>% 
  rename(as_juvenile = agecat)

#merge two tables
conviction_merge <- left_join(conviction3a, conviction3b, by = "id")

#create a new binary variable as convicted versus never convicted, resulting on if not convicted as adult (=1) and as juvenile(=1), then not convicted (=1), otherwise convicted (=2)
conviction_merge$convicted <- if_else(conviction_merge$as_adult == 1 & conviction_merge$as_juvenile == 1, 1, 2)

conviction_merge$convicted <- factor(conviction_merge$convicted,
                              levels = c(1,2),
                              labels = c("never", "atleastonce"))
```

Variable were then merged together in one file
```{r, mysize = TRUE, size="\\scriptsize"}
#transform id as factor in the predictor datafile
predictor_1$id <- as.factor(predictor_1$id)

#merge
conviction_full <- left_join(predictor_1, conviction_merge, by = "id")
```


##QUESTION 2
Report several (but not too many!) graphs and tables â€“ choose these prudently, and discuss each graph or table you include.  

Because I selected numerous potential predictors, a first look is necessary to know what is worth exploring further. Furthermore, bearing in mind that the variable convicted "as_juvenile" will be used as IV, according to the questions which is found early predictors (so, for ore accuracy, only juvenile delinguency will be used. This can be discussed, also because I could have taken the 10-13yo delinquency also, but not adult delinquency since so many other variables could be predictors. But there is not point to argue about that here.)
```{r, mysize = TRUE, size="\\scriptsize"}
#transform id variable as numeric
conviction_full$id <- as.numeric(conviction_full$id)

#have a look to the deliquency rate
conviction_full$as_juvenile <- factor(conviction_full$as_juvenile,
                              levels = c(1,2),
                              labels = c("Never", "At least once"))
table(conviction_full$as_juvenile)
```
Result is 327 (80%) of non delinquent and 84 (20%) delinquent in our sample


```{r, mysize = TRUE, size="\\scriptsize", fig.margin = TRUE}
#some descriptive/explorative data
ggplot(data = conviction_full, aes(x = as.factor(disc_dad)))+
  geom_bar(aes(y = ..prop.., group = 2))+
  facet_wrap(~as_juvenile)+
  theme_bw()+
  labs(title = "Figure 1
       Repartition of the father's discipline type according to juvenile child conviction",
       x = "Father's discipline type",
       y = "Proportion of child (%)")

ggplot(data = conviction_full, aes(x = disc_mum))+
  geom_bar(aes(y = ..prop.., group = 2))+
  facet_wrap(~as_juvenile)+
  theme_bw()+
  labs(title = "Figure 2
       Repartition of the mother's discipline type according to juvenile child conviction",
       x = "Mother's discipline type",
       y = "Proportion of child (%)")

ggplot(data = conviction_full, aes(x = familysize))+
  geom_bar(aes(y = ..prop.., group = 2))+
  facet_wrap(~as_juvenile)+
  theme_bw()+
  labs(title = "Figure 3
       Repartition of the family size according to juvenile child conviction",
       x = "Family size",
       y = "Proportion of child (%)")

ggplot(data = conviction_full, aes(x = job_dad))+
  geom_bar(aes(y = ..prop.., group = 2))+
  facet_wrap(~as_juvenile)+
  theme_bw()+
  labs(title = "Figure 4
       Repartition of the father's job statute according to juvenile child conviction",
       x = "Father's job statute",
       y = "Proportion of child (%)")

ggplot(data = conviction_full, aes(x = iq))+
  geom_bar(aes(y = ..prop.., group = 2))+
  facet_wrap(~as_juvenile)+
  theme_bw()+
  labs(title = "Figure 5
       Repartition of the IQ score range according to juvenile child conviction",
       x = "IQ score range",
       y = "Proportion of child (%)")

kable(table(conviction_full$as_juvenile, conviction_full$friends), caption = 'Table 1. Count of friends categories in each conviction case')
kable(table(conviction_full$as_juvenile, conviction_full$withdrawn), caption = 'Table 2. Count of withdrawn condition in each conviction case')
kable(table(conviction_full$as_juvenile, conviction_full$attitude_dad), caption = 'Table 3. Count of attitude of the father in each conviction case')
kable(table(conviction_full$as_juvenile, conviction_full$iq), caption = 'Table 4. Count of IQ categories in each conviction case')
kable(table(conviction_full$as_juvenile, conviction_full$popularity), caption = 'Table 5. Count of popularity categories in each conviction case')
kable(table(conviction_full$as_juvenile, conviction_full$attendance), caption = 'Table 6. Count of attendance categories in each conviction case')
```
From this first exploration, we can already guess that both family size and IQ should have a good prediction on the child conviction. Indeed, there is a crossed pattern in both cases, resulting on a bigger family (Figure 3) as well as a lower IQ score (Figure 5) for convicted that not convicted child. However, there is a higher proportion of bad discipline (especially harsh) in father's and mother's discipline (Figure 1 and 2), which should results on a correlation in these two variable, and on a potential (but low) prediction. Finally, the job of the father is rated more flucuent for convicted childs, which could also be a predictor (Figure 4). According to the frequency table, we should expect a prediction of the number of friends as well. The other predictors are not that clear. 


```{r, mysize = TRUE, size="\\scriptsize"}
#create the final dataset for the predictor model
final_delinquency <-
  conviction_full %>% 
  select(as_juvenile, disc_dad, disc_mum, familysize, job_dad, friends, withdrawn, attitude_dad, iq, popularity, attendance)

#convert predictors as numeric
final_delinquency <- data.frame(lapply(final_delinquency, function(x) as.numeric(as.factor(x))))

#explore the potentiel correlations (to deduce potentuel interactions)
pairs.panels(final_delinquency, stars = TRUE)
```

It seems to have interesting correlations between delinquency and mum discipline (as expected), familysize, job of the father, attitude of the father, and intelligence coefficient. Then, discipline of the father and the mother are also correlated, which could be enter in the model as an interaction (and makes sense). The number of friends is correlated with the withdrawn, which could also be add as an interaction though. 

##QUESTION 3
```{r, mysize = TRUE, size="\\scriptsize"}
#set seed and split for the model
set.seed(23)
delinquency_train <- sample_frac(final_delinquency, .50)
delinquency_test <- setdiff(final_delinquency, delinquency_train)

#convert id into factor
delinquency_train$as_juvenile <- as.factor(delinquency_train$as_juvenile)
delinquency_test$as_juvenile <- as.factor(delinquency_test$as_juvenile)

#remove missing data
delinquency_test = na.omit(delinquency_test)
```

Because we have a binomial variable to predict, let's use a logistic regression.
```{r, mysize = TRUE, size="\\scriptsize"}
#try a linear model with simple effects
model1 <- glm(as_juvenile ~ disc_dad + disc_mum + familysize + job_dad + friends + withdrawn + attitude_dad + iq + popularity + attendance, data = delinquency_train, family = "binomial")
summary(model1)

#find R2 and odds ratio
NagelkerkeR2(model1)
exp(coef(model1))

#find the classification accuracy of the model
predict1 <- predict(model1, newdata = delinquency_test)
#confusionMatrix(predict1, delinquency_test$as_juvenile)

```
The confusionMatrix command has a problem resulting on "error: 'data' and 'reference' should be factors with the same levels", again. I do not understand why, because everything is similar in both of my train and test subsets when I check the structure, etc. I made numerous research on the Internet, without any success. I will therefore miss the classification accuracy rate, sensitivity and specificity. Thus, I gave up, again. 

However, I cannot interpret my model more that just saying that only the size of the family and the number of friends before 10 years old seem to predict the juvenile delinquency, which was expected according to the data exploration. The fit of the model is however not so bad with a R2 = .23. I do not know how to interpret the odds ratio clarely, but it seems to be something like: the probability to commit a delictual event (= the probability to go from 1 to 2) increases of 0.70 each time we pass from one value to another on discipline of the father... That does not make sense, especially because all the data in this file are categorical. 

However, I will try to improve this model including interactions
```{r, mysize = TRUE, size="\\scriptsize"}
#try a second model adding interactions
model2 <- glm(as_juvenile ~ disc_dad*disc_mum + familysize + job_dad + friends*withdrawn + attitude_dad + iq + popularity + attendance, data = delinquency_train, family = "binomial")
summary(model2)

NagelkerkeR2(model2)
exp(coef(model2))

predict2 <- predict(model2, newdata = delinquency_test)
#confusionMatrix(predict2, delinquency_test$as_juvenile)
```

I do have the same problem with the confusionMatrix, which make harder the comparison of my two models. However, I can already observe that there are more significant factors in this model () and the model fits well the dataset, even a little bit less (R2 = 28). The odds ratio are a lot higher, but once again, I do not know how to interpret. The expected predictor are not always present, especially the IQ which showed a quite high distinctiveness between both child conviction statutes. However, withdraws was not especially expected to have an effect, but seems to have one.

It does make sense (to me) to try another model, as a classification model (three), because all of our predictors are categorical variables, meaning that the difference between 1, 2,3, etc is not a constant value. So let's try that.
```{r, mysize = TRUE, size="\\scriptsize", fig.margin = TRUE}
#create and plot the tree model
delinquency_tree = tree(as_juvenile ~ ., data = delinquency_train)
plot(delinquency_tree)                                      
text(delinquency_tree, pretty = 1)

#explore the model
summary(delinquency_tree)
```

We can see that this model is quite interesting. With a quite low error rate (14%), we can see that the most discriminant factor (predictor) is familysize, which similar to the importance it has on the logistic regression model. However, I do not think this model is really relevant neither in our case, especially because all the output expect one is 1 (= no delinquency). 

We may try something else, using cross-validation to find an alpha and use it to prune the tree
```{r, mysize = TRUE, size="\\scriptsize", fig.margin = TRUE}
cv_delinquency_tree <- cv.tree(delinquency_tree)
plot(cv_delinquency_tree$size, cv_delinquency_tree$dev, type = "b")
```
According to this graph, I decided to keep only 5
```{r, mysize = TRUE, size="\\scriptsize", fig.margin = TRUE}
prune_delinquency_tree = prune.tree(delinquency_tree, best = 5)
plot(prune_delinquency_tree)
text(prune_delinquency_tree, pretty = 1)

summary(prune_delinquency_tree)
```
From this new classification, we have an identical misclassification error rate (14%) and this models is not really relevant neither. The idea here could be: the more your family is big, your popularity low before 10 years old, the discipline of your dad "average" before 10 years old and your IQ low before 10 years old, the more likely you will "be a delinquent" as juvenile.
Finally, this tree model is absolutely not a good choice for our dataset. The regression model showed better results, and is theoriticaly more relevant to use. This tree step may have been completely useless.

#Conclusion
It is hard to conclude here. Firstly, because I have not succeed on the assignement (no confusionMatrix, not enough knowledge on how to choose a model, not enough reflexion and knowledge on potential cross-validation/bootstapping/assumptions/step to follow/etc). Secondly, because the dataset is huge, and I honestly do not know if I had to predict conviction in whole life, as juvenile, as adult, etc. as well as if I have to keep avery step data of only before a certain age as I did, according to this "early" predictor instruction. However, we can say that it should be possible (and researchers did it, with all my respect) to predict such a behavior with some well picked variables. There is definitely something interesting to say about this dataset, and the best model I constructed is the second logistic regression, with the interactions. 

#Link to GitHub repository
https://github.com/TaniaWittwer/Exam_1.git
